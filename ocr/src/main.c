#include "../include/neural_net.h"
#include "../include/utils.h"
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <errno.h>
#include <math.h>

// --- PARAM√àTRES DE BASE (AJUST√âS POUR VOTRE DATASET) ---
#define INPUT_DIM 1024       // 32 * 32 pixels
#define HIDDEN_DIM 256        // Taille de la couche cach√©e
#define OUTPUT_DIM ALPHABET_SIZE // 26 lettres
#define MAX_SAMPLES 450      // Nombre EXACT de vos √©chantillons (lettres)

// --- Chemin vers le dataset g√©n√©r√© par Python ---
#define TRAIN_DATA_FILE "data/alphabet_train_augmented"
#define TRAIN_SPLIT_RATIO 0.8 // 80% pour l'entra√Ænement, 20% pour la validation

// =========================================================================
// Fonction pour charger les donn√©es (adapt√©e pour le format 1024 floats)
// =========================================================================
int load_dataset(const char *filename, float ***inputs, float ***targets, int *sample_count) {
    FILE *f = fopen(filename, "r");
    if (!f) {
        perror("‚ùå Erreur: Impossible d'ouvrir le fichier de donn√©es");
        return 0;
    }

    // Allocation pour les pointeurs
    float **in_data = malloc(MAX_SAMPLES * sizeof(float*));
    float **tar_data = malloc(MAX_SAMPLES * sizeof(float*));
    if (!in_data || !tar_data) {
        printf("‚ùå Erreur fatale: √âchec de l'allocation pour les pointeurs de dataset.\n");
        if (in_data) free(in_data);
        if (tar_data) free(tar_data);
        fclose(f);
        return 0;
    }

    int count = 0;
    char letter;
    // Boucle de lecture: s'arr√™te si le fichier se termine OU si MAX_SAMPLES est atteint
    while (fscanf(f, " %c", &letter) == 1 && count < MAX_SAMPLES) {
        // Allocation de la m√©moire pour l'entr√©e (1024 floats) et la sortie (26 floats)
        in_data[count] = malloc(INPUT_DIM * sizeof(float));
        tar_data[count] = calloc(OUTPUT_DIM, sizeof(float)); 
        
        // Mise en place du label cible (One-Hot Encoding)
        if (letter >= 'A' && letter <= 'Z') {
             tar_data[count][letter - 'A'] = 1.0f;
        } else {
            // G√©rer les caract√®res invalides (bien que generate_dataset.py devrait l'emp√™cher)
            free(in_data[count]);
            free(tar_data[count]);
            continue;
        }

        // Lecture des 1024 pixels (float)
        for (int i = 0; i < INPUT_DIM; i++) {
            if (fscanf(f, "%f", &in_data[count][i]) != 1) {
                printf("‚ùå Erreur de formatage √† la ligne %d (pixel %d)\n", count + 1, i + 1);
                // Lib√©ration de la m√©moire et sortie d'erreur...
                fclose(f);
                return 0;
            }
        }

        count++;
    }
    
    // Fermeture du fichier
    fclose(f);
    
    // D√©finition des pointeurs de sortie
    *inputs = in_data;
    *targets = tar_data;
    *sample_count = count;

    return 1;
}

// =========================================================================
// Fonction principale
// =========================================================================
int main(void) {
    // --- 1. Initialisation ou Chargement du r√©seau ---
    int input_size = INPUT_DIM;
    int hidden_size = HIDDEN_DIM;
    int output_size = OUTPUT_DIM;

    // Tente de charger un r√©seau existant pour reprendre l'entra√Ænement
    NeuralNetwork *nn = load_network("trained_network.bin");
    if (!nn) {
        printf("‚ö†Ô∏è Aucun r√©seau existant (trained_network.bin) trouv√©. Initialisation d'un nouveau r√©seau...\n");
        nn = init_network(input_size, hidden_size, output_size);
    } else {
        printf("‚úÖ Reprise de l'entra√Ænement avec le r√©seau charg√©...\n");
    }
    if (!nn) return 1;

    // --- 2. Chargement du dataset ---
    float **all_inputs;
    float **all_targets;
    int total_samples;

    if (!load_dataset(TRAIN_DATA_FILE, &all_inputs, &all_targets, &total_samples)) {
        free_network(nn);
        return 1;
    }
    
    // --- 3. S√©paration en ensembles d'entra√Ænement (Train) et de validation (Test) ---
    // Utilise 80% des donn√©es pour l'entra√Ænement et 20% pour la validation
    int train_count = (int)floor(total_samples * TRAIN_SPLIT_RATIO); // 450 * 0.8 = 360
    int test_count = total_samples - train_count;               // 450 - 360 = 90

    float **train_inputs = all_inputs;
    float **train_targets = all_targets;
    float **test_inputs = all_inputs + train_count;
    float **test_targets = all_targets + train_count;

    printf("\nüìä Dataset charg√©: %d √©chantillons au total.\n", total_samples);
    printf("   - Entra√Ænement (Train): %d √©chantillons.\n", train_count);
    printf("   - Validation (Test): %d √©chantillons.\n", test_count);

    // --- 4. Param√®tres d'entra√Ænement ---
    float lr = 0.05f;  // Learning Rate initial (Augment√© pour sortir du plateau)
    int epochs = 3000; // Nombre d'√©poques pour la nouvelle session
    
    // Variables pour la s√©lection du meilleur mod√®le (Early Stopping)
    float best_accuracy = 0.0f; 
    int best_epoch = 0;
    
    // Calculer la pr√©cision initiale du mod√®le charg√© pour d√©marrer la comparaison
    int correct_initial = validate(nn, test_inputs, test_targets, test_count);
    best_accuracy = (float)correct_initial / test_count;
    if (best_accuracy > 0.0f) {
        printf("üéØ Pr√©cision de d√©part (mod√®le charg√©): %.2f%%\n", best_accuracy * 100.0f);
        best_epoch = -1; // Indique que c'est une pr√©cision pr√©-entra√Ænement
    }


    printf("\nüîß D√©but de l'entra√Ænement sur %d √©poques (LR initial: %.4f)...\n", epochs, lr);

    // --- 5. Boucle d'entra√Ænement ---
    for (int epoch = 1; epoch <= epochs; epoch++) {
        long start = get_time_ms();
        
        // Entra√Ænement sur la partie "train"
        train_epoch(nn, train_inputs, train_targets, train_count, lr);
        
        // Validation sur la partie "test"
        int correct = validate(nn, test_inputs, test_targets, test_count);
        float current_accuracy = (float)correct / test_count;

        long end = get_time_ms();
        
        printf("Epoch %d/%d termin√©e (%ld ms). Pr√©cision Validation: %d/%d (%.2f%%)", 
               epoch, epochs, end - start, correct, test_count, current_accuracy * 100.0f);
        
        // --- Logique de Sauvegarde Conditionnelle (Early Stopping) ---
        if (current_accuracy > best_accuracy) {
            best_accuracy = current_accuracy;
            best_epoch = epoch;
            
            // üíæ SAUVEGARDE DU NOUVEAU MEILLEUR MOD√àLE
            save_network(nn, "trained_network.bin");
            printf(" >>> NOUVEAU MEILLEUR MOD√àLE SAUVEGARD√â (%.2f%%)", best_accuracy * 100.0f);
        }
        printf("\n");
        
        // üí° Ajuster le Learning Rate pour aider √† sortir des minima locaux
        if (epoch % 200 == 0) { // R√©duit le LR tous les 200 √©poques
            lr *= 0.7f; 
            printf("--- Learning Rate ajust√© √†: %.4f ---\n", lr); 
        }
    }

    // --- 6. Fin et Lib√©ration ---
    printf("\n‚úÖ Entra√Ænement termin√©. Meilleure pr√©cision obtenue: %.2f%% √† l'√âpoque %d.\n", 
           best_accuracy * 100.0f, best_epoch);

    // Lib√©ration de la m√©moire du dataset
    for (int i = 0; i < total_samples; i++) {
        free(all_inputs[i]);
        free(all_targets[i]);
    }
    free(all_inputs);
    free(all_targets);

    // Lib√©ration de la m√©moire du r√©seau
    free_network(nn);

    return 0;
}
